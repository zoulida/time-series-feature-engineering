# -*- coding: utf-8 -*-
"""
ICæ£€æµ‹å·¥ä½œæµæ‰¹é‡ç‰ˆ - é‡æ„ç‰ˆ
ä¸»å·¥ä½œæµåè°ƒå™¨ï¼Œè°ƒç”¨å„ä¸ªæ­¥éª¤æ¨¡å—å®ŒæˆICæ£€æµ‹æµç¨‹

ä¸»è¦åŠŸèƒ½ï¼š
1. åè°ƒå„ä¸ªæ­¥éª¤æ¨¡å—çš„æ‰§è¡Œ
2. ç®¡ç†é…ç½®å’Œé”™è¯¯å¤„ç†
3. æä¾›ç»Ÿä¸€çš„æ‰§è¡Œå…¥å£
4. æ”¯æŒè¿›åº¦ç›‘æ§å’Œæ€§èƒ½ç»Ÿè®¡
"""

import sys
import os
import logging
import time
from datetime import datetime

# ç¦ç”¨Numba GPUåŠ é€Ÿä»¥é¿å…CUDAç‰ˆæœ¬è­¦å‘Š
os.environ['NUMBA_DISABLE_JIT'] = '1'
os.environ['NUMBA_CUDA_DISABLE'] = '1'
os.environ['NUMBA_DISABLE_CUDA'] = '1'

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥æ¨¡å—
sys.path.append(os.path.join(os.path.dirname(__file__), 'shared'))

# å¯¼å…¥å„ä¸ªæ­¥éª¤æ¨¡å—
from step1_get_stock_data_batch import StockDataBatchFetcher
from step2_select_factors_batch import FactorBatchSelector
from step3_generate_training_data_batch import TrainingDataBatchGenerator
from step4_ic_analysis_batch import ICBatchAnalyzer

# å¯¼å…¥å…±äº«ç»„ä»¶
from shared import MemoryMonitor, ProgressTracker, check_dependencies, cleanup_old_files

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ic_workflow_batch.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class WorkflowConfig:
    """å·¥ä½œæµé…ç½®ç±» - ç®¡ç†æ‰€æœ‰è¿è¡Œå‚æ•°å’Œæ€§èƒ½è®¾ç½®"""
    
    def __init__(self):
        # æµ‹è¯•é…ç½® - ç”¨äºå¿«é€ŸéªŒè¯åŠŸèƒ½
        self.test_mode = False  # æ˜¯å¦å¯ç”¨æµ‹è¯•æ¨¡å¼ï¼ˆTrue=æµ‹è¯•æ¨¡å¼ï¼ŒFalse=ç”Ÿäº§æ¨¡å¼ï¼‰
        self.test_stocks = 100  # æµ‹è¯•æ¨¡å¼è‚¡ç¥¨æ•°é‡ï¼ˆå¿«é€ŸéªŒè¯ç”¨ï¼Œå»ºè®®100-500åªï¼‰
        self.test_factors = 50  # æµ‹è¯•æ¨¡å¼å› å­æ•°é‡ï¼ˆå¿«é€ŸéªŒè¯ç”¨ï¼Œå»ºè®®20-100ä¸ªï¼‰
        
        # ç”Ÿäº§é…ç½® - ç”¨äºå¤§è§„æ¨¡æ•°æ®åˆ†æ
        self.production_stocks = 5000  # ç”Ÿäº§æ¨¡å¼è‚¡ç¥¨æ•°é‡ï¼ˆæœ€å¤§æ”¯æŒ5000åªè‚¡ç¥¨ï¼‰
        self.production_factors = 500  # ç”Ÿäº§æ¨¡å¼å› å­æ•°é‡ï¼ˆç»Ÿä¸€å› å­åº“å…¨éƒ¨å› å­ï¼‰
        
        # åˆ†æ‰¹é…ç½® - ä¼˜åŒ–å†…å­˜ä½¿ç”¨å’Œæ€§èƒ½
        self.batch_size = 500  # æ¯æ‰¹å¤„ç†çš„è‚¡ç¥¨æ•°é‡ï¼ˆå¹³è¡¡å†…å­˜ä½¿ç”¨å’Œå¤„ç†æ•ˆç‡ï¼‰
        self.max_memory_gb = 4  # æœ€å¤§å†…å­˜ä½¿ç”¨é™åˆ¶(GB)ï¼ˆè¶…è¿‡ä¼šè§¦å‘åƒåœ¾å›æ”¶ï¼‰
        
        # å¹¶è¡Œé…ç½® - æå‡è®¡ç®—æ•ˆç‡
        self.max_workers = 4  # æœ€å¤§å¹¶è¡Œè¿›ç¨‹æ•°ï¼ˆé¿å…ç³»ç»Ÿè¿‡è½½ï¼Œå»ºè®®2-8ä¸ªï¼‰
        self.enable_parallel = True  # æ˜¯å¦å¯ç”¨å¹¶è¡Œå¤„ç†ï¼ˆTrue=å¤šè¿›ç¨‹ï¼ŒFalse=å•è¿›ç¨‹ï¼‰
        
        # æ¢å¤é…ç½® - æ”¯æŒæ–­ç‚¹ç»­ä¼ 
        self.checkpoint_interval = 100  # æ£€æŸ¥ç‚¹é—´éš”ï¼ˆæ¯å¤„ç†å¤šå°‘åªè‚¡ç¥¨ä¿å­˜ä¸€æ¬¡ï¼‰
        self.enable_recovery = True  # æ˜¯å¦å¯ç”¨é”™è¯¯æ¢å¤ï¼ˆæ”¯æŒä»ä¸­æ–­ç‚¹ç»§ç»­è¿è¡Œï¼‰


class BatchICWorkflow:
    """æ‰¹é‡ICæ£€æµ‹å·¥ä½œæµ - ä¸»åè°ƒå™¨
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. åè°ƒå„ä¸ªæ­¥éª¤æ¨¡å—çš„æ‰§è¡Œ
    2. ç®¡ç†é…ç½®å’Œé”™è¯¯å¤„ç†
    3. æä¾›ç»Ÿä¸€çš„æ‰§è¡Œå…¥å£
    4. æ”¯æŒè¿›åº¦ç›‘æ§å’Œæ€§èƒ½ç»Ÿè®¡
    """
    
    def __init__(self, config=None, batch_config=None):
        """
        åˆå§‹åŒ–æ‰¹é‡ICæ£€æµ‹å·¥ä½œæµ
        
        Args:
            config: å·¥ä½œæµé…ç½®å¯¹è±¡
            batch_config: æ‰¹é‡é…ç½®å¯¹è±¡ï¼ˆæ¥è‡ªconfig_batch.pyï¼‰
        """
        self.config = config or WorkflowConfig()
        self.batch_config = batch_config  # ä¿å­˜batch_configç”¨äºå› å­é€‰æ‹©
        self.memory_monitor = MemoryMonitor(self.config.max_memory_gb)
        self.data_dir = os.path.join(os.path.dirname(__file__), 'data')
        os.makedirs(self.data_dir, exist_ok=True)
        
        # æ¸…ç©ºä¹‹å‰ç”Ÿæˆçš„æ•°æ®æ–‡ä»¶ï¼ˆé¿å…ç£ç›˜ç©ºé—´æµªè´¹ï¼‰
        self._cleanup_old_files()
    
    def _cleanup_old_files(self):
        """æ¸…ç†æ—§æ–‡ä»¶"""
        file_patterns = [
            'training_data_batch_*.csv',  # è®­ç»ƒæ•°æ®æ–‡ä»¶
            'ic_results_batch_*.json',   # ICåˆ†æç»“æœJSON
            'ic_report_batch_*.csv',     # ICåˆ†ææŠ¥å‘ŠCSV
            'selected_stock_codes.txt',  # é€‰ä¸­çš„è‚¡ç¥¨ä»£ç 
            'selected_factors.csv',      # é€‰ä¸­çš„å› å­CSV
            'selected_factors.json',     # é€‰ä¸­çš„å› å­JSON
            'workflow_checkpoint.pkl'    # æ£€æŸ¥ç‚¹æ–‡ä»¶
        ]
        cleanup_old_files(self.data_dir, file_patterns)
    
    def get_workflow_config(self):
        """è·å–å·¥ä½œæµé…ç½®"""
        if self.config.test_mode:
            return {
                'stocks': self.config.test_stocks,
                'factors': self.config.test_factors,
                'mode': 'æµ‹è¯•æ¨¡å¼'
            }
        else:
            return {
                'stocks': self.config.production_stocks,
                'factors': self.config.production_factors,
                'mode': 'ç”Ÿäº§æ¨¡å¼'
            }
    
    def run_batch_workflow(self):
        """è¿è¡Œæ‰¹é‡å·¥ä½œæµ"""
        try:
            logger.info("=" * 60)
            logger.info("ICæ£€æµ‹å·¥ä½œæµæ‰¹é‡ç‰ˆå¼€å§‹æ‰§è¡Œ")
            logger.info("=" * 60)
            
            # è·å–é…ç½®
            workflow_config = self.get_workflow_config()
            logger.info(f"è¿è¡Œæ¨¡å¼: {workflow_config['mode']}")
            logger.info(f"è‚¡ç¥¨æ•°é‡: {workflow_config['stocks']}")
            logger.info(f"å› å­æ•°é‡: {workflow_config['factors']}")
            
            # æ£€æŸ¥ä¾èµ–
            if not check_dependencies(self.memory_monitor):
                return False
            
            # å¼€å§‹æ–°çš„å·¥ä½œæµ
            return self._start_new_workflow(workflow_config)
            
        except Exception as e:
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")
            return False
    
    def _start_new_workflow(self, workflow_config):
        """å¼€å§‹æ–°çš„å·¥ä½œæµ - æ‰§è¡Œå®Œæ•´çš„ICæ£€æµ‹æµç¨‹
        
        å·¥ä½œæµåŒ…å«4ä¸ªä¸»è¦æ­¥éª¤ï¼š
        1. è·å–è‚¡ç¥¨æ•°æ® - ä»æ•°æ®æºåŠ è½½æŒ‡å®šæ•°é‡çš„è‚¡ç¥¨æ•°æ®
        2. é€‰æ‹©å› å­ - ä»ç»Ÿä¸€å› å­åº“ä¸­é€‰æ‹©æŒ‡å®šæ•°é‡çš„å› å­
        3. ç”Ÿæˆè®­ç»ƒæ•°æ® - è®¡ç®—å› å­å€¼å’Œæ”¶ç›Šç‡ï¼Œåˆ†æ‰¹å¤„ç†é¿å…å†…å­˜æº¢å‡º
        4. ICåˆ†æ - è®¡ç®—æ¯ä¸ªå› å­çš„ä¿¡æ¯ç³»æ•°ï¼Œè¯„ä¼°å› å­æœ‰æ•ˆæ€§
        
        Args:
            workflow_config (dict): å·¥ä½œæµé…ç½®å‚æ•°
            
        Returns:
            bool: å·¥ä½œæµæ˜¯å¦æ‰§è¡ŒæˆåŠŸ
        """
        # åˆ›å»ºè¿›åº¦è·Ÿè¸ªå™¨
        total_steps = 4  # 4ä¸ªä¸»è¦æ­¥éª¤
        progress_tracker = ProgressTracker(total_steps)
        
        try:
            total_start_time = time.time()
            
            # æ­¥éª¤1: è·å–è‚¡ç¥¨æ•°æ®
            step1_start = time.time()
            progress_tracker.update("è·å–è‚¡ç¥¨æ•°æ®", f"ç›®æ ‡: {workflow_config['stocks']}åªè‚¡ç¥¨")
            
            stock_fetcher = StockDataBatchFetcher(self.config, self.memory_monitor)
            stock_data = stock_fetcher.get_stock_data_batch(workflow_config['stocks'])
            
            step1_time = time.time() - step1_start
            logger.info(f"æ­¥éª¤1å®Œæˆï¼Œè€—æ—¶: {step1_time:.2f}ç§’")
            
            # æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
            memory_info = self.memory_monitor.check_memory()
            if not memory_info['is_safe']:
                self.memory_monitor.force_gc()
            
            # æ­¥éª¤2: é€‰æ‹©å› å­
            step2_start = time.time()
            progress_tracker.update("é€‰æ‹©å› å­", f"ç›®æ ‡: {workflow_config['factors']}ä¸ªå› å­")
            
            factor_selector = FactorBatchSelector(self.config, self.data_dir, self.batch_config)
            selected_factors = factor_selector.select_factors_batch(workflow_config['factors'])
            
            step2_time = time.time() - step2_start
            logger.info(f"æ­¥éª¤2å®Œæˆï¼Œè€—æ—¶: {step2_time:.2f}ç§’")
            
            # æ­¥éª¤3: ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆåˆ†æ‰¹å¤„ç†ï¼‰
            step3_start = time.time()
            progress_tracker.update("ç”Ÿæˆè®­ç»ƒæ•°æ®", "åˆ†æ‰¹å¤„ç†ä¸­...")
            
            training_generator = TrainingDataBatchGenerator(self.config, self.memory_monitor)
            training_data = training_generator.generate_training_data_batch(stock_data, selected_factors, progress_tracker)
            
            step3_time = time.time() - step3_start
            logger.info(f"æ­¥éª¤3å®Œæˆï¼Œè€—æ—¶: {step3_time:.2f}ç§’")
            
            # æ­¥éª¤4: ICåˆ†æ
            step4_start = time.time()
            progress_tracker.update("ICåˆ†æ", f"åˆ†æ{len(selected_factors)}ä¸ªå› å­")
            
            ic_analyzer = ICBatchAnalyzer(self.config, self.data_dir)
            ic_results = ic_analyzer.perform_ic_analysis_batch(training_data, selected_factors)
            
            step4_time = time.time() - step4_start
            logger.info(f"æ­¥éª¤4å®Œæˆï¼Œè€—æ—¶: {step4_time:.2f}ç§’")
            
            total_time = time.time() - total_start_time
            
            # è¾“å‡ºè¯¦ç»†çš„æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
            self._display_performance_summary(step1_time, step2_time, step3_time, step4_time, total_time)
            
            # è‡ªåŠ¨è¿è¡ŒICç»“æœåˆ†æ
            self._run_ic_analysis()
            
            return True
            
        except Exception as e:
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")
            return False
    
    def _display_performance_summary(self, step1_time, step2_time, step3_time, step4_time, total_time):
        """æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡æ‘˜è¦"""
        logger.info("=" * 60)
        logger.info("å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
        logger.info("=" * 60)
        logger.info("å„é˜¶æ®µè€—æ—¶ç»Ÿè®¡:")
        logger.info(f"  æ­¥éª¤1 - è·å–è‚¡ç¥¨æ•°æ®: {step1_time:.2f}ç§’ ({step1_time/total_time*100:.1f}%)")
        logger.info(f"  æ­¥éª¤2 - é€‰æ‹©å› å­: {step2_time:.2f}ç§’ ({step2_time/total_time*100:.1f}%)")
        logger.info(f"  æ­¥éª¤3 - ç”Ÿæˆè®­ç»ƒæ•°æ®: {step3_time:.2f}ç§’ ({step3_time/total_time*100:.1f}%)")
        logger.info(f"  æ­¥éª¤4 - ICåˆ†æ: {step4_time:.2f}ç§’ ({step4_time/total_time*100:.1f}%)")
        logger.info(f"  æ€»è€—æ—¶: {total_time:.2f}ç§’")
        logger.info("=" * 60)
    
    def _run_ic_analysis(self):
        """è¿è¡ŒICç»“æœåˆ†æ"""
        try:
            logger.info("=" * 60)
            logger.info("å¼€å§‹ICç»“æœåˆ†æ")
            logger.info("=" * 60)
            
            # æ„å»ºanalyze_ic_results.pyçš„è·¯å¾„
            analyze_script_path = os.path.join(self.data_dir, 'analyze_ic_results.py')
            
            if not os.path.exists(analyze_script_path):
                logger.warning(f"ICåˆ†æè„šæœ¬ä¸å­˜åœ¨: {analyze_script_path}")
                return
            
            # è¿è¡ŒICåˆ†æè„šæœ¬
            import subprocess
            result = subprocess.run(
                [sys.executable, analyze_script_path],
                cwd=self.data_dir,
                capture_output=True,
                text=True,
                encoding='gbk',  # ä½¿ç”¨gbkç¼–ç å¤„ç†ä¸­æ–‡è¾“å‡º
                errors='ignore'  # å¿½ç•¥ç¼–ç é”™è¯¯
            )
            
            if result.returncode == 0:
                logger.info("ICç»“æœåˆ†æå®Œæˆ")
                print("\n" + "=" * 80)
                print("ICç»“æœåˆ†ææŠ¥å‘Š")
                print("=" * 80)
                print(result.stdout)
            else:
                logger.error(f"ICåˆ†æè„šæœ¬æ‰§è¡Œå¤±è´¥: {result.stderr}")
                
        except Exception as e:
            logger.error(f"è¿è¡ŒICåˆ†æå¤±è´¥: {str(e)}")


def main():
    """ä¸»å‡½æ•° - ç¨‹åºå…¥å£ç‚¹
    
    æ‰§è¡Œå®Œæ•´çš„ICæ£€æµ‹å·¥ä½œæµï¼š
    1. åˆ›å»ºé…ç½®å¯¹è±¡ï¼ˆåŒ…å«æ‰€æœ‰è¿è¡Œå‚æ•°ï¼‰
    2. åˆå§‹åŒ–æ‰¹é‡å·¥ä½œæµå®ä¾‹
    3. è¿è¡Œå·¥ä½œæµï¼ˆåŒ…å«4ä¸ªä¸»è¦æ­¥éª¤ï¼‰
    4. è¾“å‡ºæ‰§è¡Œç»“æœ
    
    é…ç½®è¯´æ˜ï¼š
    - æµ‹è¯•æ¨¡å¼ï¼š100åªè‚¡ç¥¨ï¼Œ50ä¸ªå› å­ï¼ˆå¿«é€ŸéªŒè¯ï¼‰
    - ç”Ÿäº§æ¨¡å¼ï¼š5000åªè‚¡ç¥¨ï¼Œ500ä¸ªå› å­ï¼ˆå®Œæ•´åˆ†æï¼‰
    """
    # åˆ›å»ºé…ç½®å¯¹è±¡
    config = WorkflowConfig()
    config.test_mode = True
    
    # åˆ›å»ºæ‰¹é‡å·¥ä½œæµå®ä¾‹
    workflow = BatchICWorkflow(config)
    
    # è¿è¡Œå·¥ä½œæµ
    success = workflow.run_batch_workflow()
    
    # è¾“å‡ºæ‰§è¡Œç»“æœ
    if success:
        print("ğŸ‰ æ‰¹é‡å·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼")
        print("ğŸ“ ç»“æœæ–‡ä»¶ä¿å­˜åœ¨: D:\\pythonProject\\æ—¶åºç‰¹å¾å·¥ç¨‹\\source\\ICæ£€æµ‹æ‰¹é‡\\data")
    else:
        print("âŒ æ‰¹é‡å·¥ä½œæµæ‰§è¡Œå¤±è´¥ï¼")
        sys.exit(1)


if __name__ == "__main__":
    main()
